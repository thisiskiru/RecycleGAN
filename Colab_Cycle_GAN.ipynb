{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI9e8cp4XyDD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128, 128, 64) 3072        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 64, 64, 128)  131584      sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 32, 32, 256)  525312      sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 16, 16, 512)  2099200     sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 8, 8, 512)    4196352     sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 4, 4, 512)    4196352     sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 2, 2, 512)    4196352     sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 1, 1, 512)    4196352     sequential_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 2, 2, 512)    4196352     sequential_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 2, 1024)   0           sequential_8[0][0]               \n",
      "                                                                 sequential_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 4, 4, 512)    8390656     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 1024)   0           sequential_9[0][0]               \n",
      "                                                                 sequential_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 8, 8, 512)    8390656     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 1024)   0           sequential_10[0][0]              \n",
      "                                                                 sequential_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16, 16, 512)  8390656     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 1024) 0           sequential_11[0][0]              \n",
      "                                                                 sequential_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 32, 32, 256)  4195328     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 512)  0           sequential_12[0][0]              \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 64, 64, 128)  1049088     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 256)  0           sequential_13[0][0]              \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_14 (Sequential)      (None, 128, 128, 64) 262400      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 128 0           sequential_14[0][0]              \n",
      "                                                                 sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 3)  6147        concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 54,425,859\n",
      "Trainable params: 54,414,979\n",
      "Non-trainable params: 10,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from pix2pix_Temporal_predictor import Generator\n",
    "\n",
    "import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "x = 0\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTsv5qeIXyDb"
   },
   "source": [
    "# class eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lroy2YWsXyDi"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset_name=\"default\", img_res=(256, 256)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "        \n",
    "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('/datasets/%s/%s/*' % (self.dataset_name, data_type))#/content/drive/My Drive\n",
    "        \n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "        #print(path)\n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                #img = scipy.misc.imresize(img, self.img_res)\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            else:\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.array(imgs)/127.5 - 1.\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('/datasets/%s/%sA/*' % (self.dataset_name, data_type))#/content/drive/My Drive/cycleGAN\n",
    "        path_B = glob('/datasets/%s/%sB/*' % (self.dataset_name, data_type))\n",
    "        #print(path_A)\n",
    "        \n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "\n",
    "        # Sample n_batches * batch_size from each path list so that model sees all\n",
    "        # samples from both domains\n",
    "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "                '''\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "                '''\n",
    "                img_A = cv2.resize(img_A, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "                img_B = cv2.resize(img_B, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "    def imread(self, path):\n",
    "        return cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmX4UO-AXyDm"
   },
   "outputs": [],
   "source": [
    "class DataLoader(DataLoader):\n",
    "    global x\n",
    "    def load_data_seq(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))#content/drive/My Drive/cycleGAN/\n",
    "        \n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "        #print(path)\n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                #img = scipy.misc.imresize(img, self.img_res)\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            else:\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.array(imgs)/127.5 - 1.\n",
    "\n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kpm_GMxeXyDs"
   },
   "outputs": [],
   "source": [
    "class DataLoader(DataLoader):\n",
    "    def load_batch_seq(self, batch_size=1, is_testing=False):\n",
    "        global x\n",
    "        x=batch_size + x\n",
    "        print('\\n',x,'\\n')\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))#/content/drive/My Drive/cycleGAN\n",
    "        path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))#/content/drive/My Drive/cycleGAN\n",
    "        \n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "\n",
    "        # Sample n_batches * batch_size from each path list so that model sees all\n",
    "        # samples from both domains\n",
    "        #for i in range(n_batches):\n",
    "        ba_A = path_A[x - batch_size : x]\n",
    "        ba_B = path_B[x - batch_size : x]\n",
    "            \n",
    "            \n",
    "        #path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        #path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "                '''\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "                '''\n",
    "                img_A = cv2.resize(img_A, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "                img_B = cv2.resize(img_B, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mI8wUHMmXyDw"
   },
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #sess and model of flownet2\n",
    "        self.img_cols=256\n",
    "        self.img_rows=256\n",
    "        self.channels = 3 \n",
    "        #flownet2 = initflow()\n",
    "        epsilon: int = 1e-5\n",
    "        self.img_shape = (self.img_rows, self.img_cols,self.channels) \n",
    "        self.dataset_name = '01'\n",
    "        \n",
    "        self.data_loader=DataLoader(self.dataset_name)\n",
    "        #self.mc=myclass()\n",
    "        \n",
    "        \n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1) \n",
    "        self.gf = 32                                                    \n",
    "        self.df = 64   \n",
    "        \n",
    "        \"\"\"\n",
    "        hyperparameters\n",
    "         1, lambda_cycle — controls howstrictly the cycle-consistency loss is enforced.\n",
    "         2, lambda_id — influences identity loss\n",
    "         3, lambda_opt — control optical flow difference between the two network\n",
    "        \"\"\"\n",
    "        self.lambda_cycle = 10.0  \n",
    "        self.lambda_id = 0.9 * self.lambda_cycle \n",
    "        self.lambda_opt = 10.0 \n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        self.Pa = Generator()\n",
    "        self.pb = Generator()\n",
    "        \n",
    "        #self.Pa.compile(loss = 'mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "        #self.Pb.compile(loss = 'mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "        \n",
    "        self.d_A = self.build_discriminator('d_A')\n",
    "        self.d_A.summary()\n",
    "        \n",
    "        self.d_B = self.build_discriminator('d_B')\n",
    "        self.d_B.summary()\n",
    "        \n",
    "        self.d_A.compile(loss = 'mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "        self.d_B.compile(loss = 'mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "        \n",
    "        self.g_AB = self.build_generator('g_AB')\n",
    "        self.g_AB.summary()\n",
    "        self.g_BA = self.build_generator('g_BA')\n",
    "        self.g_BA.summary()\n",
    "        \n",
    "        img_A = tf.keras.Input(shape=self.img_shape)\n",
    "        opt_A = tf.keras.Input(shape=self.img_shape)\n",
    "        img_B = tf.keras.Input(shape=self.img_shape)\n",
    "        opt_B = tf.keras.Input(shape=self.img_shape)\n",
    "        \n",
    "        print('shape of me is: ',img_A.shape[0])\n",
    "        \n",
    "        fake_B = self.g_AB(img_A)                                  \n",
    "        fake_A = self.g_BA(img_B)\n",
    "        #fake_B =myclass.flowwarp(fake_A,img_A)\n",
    "        #opt_A = exect(flownet2,[img_A,img_A])\n",
    "        #opt_B = img_B[0] \n",
    "            \n",
    "        reconstr_A = self.g_BA(fake_B)                             \n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        \n",
    "        '''\n",
    "        opt_A = exect(self.flownet2,[op1,op1])         \n",
    "        opt_B = exect(self.flownet2,[self.prevB,op2])\n",
    "        opt_Are = exect(self.flownet2,[self.prevAre,reconstr_A])\n",
    "        opt_Bre = exect(self.flownet2,[self.prevBre,reconstr_B])\n",
    "        '''\n",
    "        \n",
    "        self.prevA = img_A\n",
    "        self.prevB = img_B\n",
    "        \n",
    "        self.prevAre = reconstr_A\n",
    "        self.prevBre = reconstr_B\n",
    "        \n",
    "        img_A_id = self.g_BA(img_A)                                \n",
    "        img_B_id = self.g_AB(img_B)\n",
    "        \n",
    "        self.d_A.trainable = False                                 \n",
    "        self.d_B.trainable = False\n",
    "        \n",
    "        valid_A = self.d_A(fake_A)                                 \n",
    "        valid_B = self.d_B(fake_B)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.combined = tf.keras.Model(inputs=[img_A, img_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,    \n",
    "                                       img_A_id, img_B_id]) \n",
    "        self.combined.compile(loss=['mse', 'mse','mae', 'mae','mae', 'mae'],\n",
    "                              loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_id, \n",
    "                                            self.lambda_id],\n",
    "                              optimizer=optimizer)\n",
    "        self.combined.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_zqezVwXyD5"
   },
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_generator(self,name):\n",
    "        d0 = tf.keras.Input(self.img_shape)  \n",
    "        ''' ConvNET '''\n",
    "        d1 = self.conv2d(d0, 64, 7)              \n",
    "        d2 = self.conv2d(d1, 128, 3, 2, Ins_Norm=True)          \n",
    "        d3 = self.conv2d(d2, 256, 3, 2, Ins_Norm=True)\n",
    "        \n",
    "        ''' Residual Block '''\n",
    "        r1 = self.conv2d(d3, 256, 3, 1)\n",
    "        r2 = self.conv2d(r1, 256, 3, 1)\n",
    "        r3 = self.conv2d(r2, 256, 3, 1)\n",
    "        r4 = self.conv2d(r3, 256, 3, 1)\n",
    "        r5 = self.conv2d(r4, 256, 3, 1)\n",
    "        \n",
    "        r6 = self.resNET(r5, r4, 256, 3, 1)\n",
    "        r7 = self.resNET(r6, r3, 256, 3, 1)\n",
    "        r8 = self.resNET(r7, r2, 256, 3, 1)\n",
    "        r9 = self.resNET(r8, r1, 256, 3, 1)\n",
    "        \n",
    "        u1 = self.deconv2d(r9, 128, 3, 2, True)\n",
    "        u2 = self.deconv2d(u1, 64, 3, 2, True)\n",
    "                        \n",
    "        output_img = layers.Conv2D(self.channels, kernel_size=7, strides=(1,1), padding='same',activation='tanh')(u2) \n",
    "        x=tf.keras.Model(d0, output_img,name=name)\n",
    "        #x.Summary()\n",
    "        return x\n",
    "    \n",
    "    def build_discriminator(self,n):\n",
    "        #conv2d(layer_input, num_Filter, f_size=4, Strides=1,Ins_Norm=True,Padding='same'):\n",
    "        img=tf.keras.Input(self.img_shape)\n",
    "        d1 = self.conv2d(img, 64, 4, 2)\n",
    "        d2 = self.conv2d(d1, 128, 4, 2)\n",
    "        d3 = self.conv2d(d2, 256, 4, 2)\n",
    "        d4 = self.conv2d(d3, 512, 4, 2)  \n",
    "        d5 = self.conv2d(d4, 1, 4, 1)  \n",
    "       \n",
    "        x=tf.keras.Model(img,d5,name=n)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSAB_U7wXyD-"
   },
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        r, c = 2, 3\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)    \n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        #fake_A = self.g_BA.predict(imgs_B)\n",
    "        '''\n",
    "        cheeck here\n",
    "        '''\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                #print(gen_imgs[cnt].shape)\n",
    "                b,g,r = cv2.split(gen_imgs[cnt])       # get b,g,r\n",
    "                im_rgb = cv2.merge([r,g,b])     # switch it to rgb\n",
    "                \n",
    "                axs[i,j].imshow((im_rgb * 255).astype(np.uint8))\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('on')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kep9ICe9XyEC"
   },
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch_seq(batch_size)):\n",
    "               \n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "                # Translate images to opposite domain\n",
    "                \n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "                print(fake_A.shape,imgs_A.shape)\n",
    "                \n",
    "                ###################\n",
    "                fake_A = floweval(self.sess,self.out,fake_A[0],fake_A[0],self.tens1,self.tens2)\n",
    "                ###################\n",
    "                \n",
    "                #imagewarp()\n",
    "                \n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "                # Total discriminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "                \n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "                #print(d_loss,dA_loss,dB_loss)\n",
    "                # Train the generators\n",
    "                print(self.combined.metrics_names)\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                      [valid, valid,\n",
    "                                                       imgs_A, imgs_B,\n",
    "                                                       imgs_A, imgs_B])\n",
    "                \n",
    "                print(g_loss)\n",
    "                \n",
    "                #print('g_loss: ',g_loss)\n",
    "                # If at save interval => plot the generated image samples\n",
    "                \n",
    "                if batch_i % sample_interval * 50 == 0:\n",
    "                    self.sample_images(epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jXNeVPHQXyEJ",
    "outputId": "c4c59f25-cf1e-42db-bc16-91bac584dd50",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\thisiskiru\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Restoring parameters from ./models/LiteFlowNet2_Sintel_model\n",
      "Model: \"d_A\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "instance_normalization (Inst (None, 128, 128, 64)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 32, 32, 256)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 16, 16, 1)         8193      \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 16, 16, 1)         2         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,766,659\n",
      "Trainable params: 2,766,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"d_B\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "instance_normalization_5 (In (None, 128, 128, 64)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_6 (In (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_7 (In (None, 32, 32, 256)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "instance_normalization_8 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 16, 16, 1)         8193      \n",
      "_________________________________________________________________\n",
      "instance_normalization_9 (In (None, 16, 16, 1)         2         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 16, 16, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,766,659\n",
      "Trainable params: 2,766,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"g_AB\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 256, 256, 64) 9472        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, 256, 256, 64) 128         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 128, 128, 128 73856       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, 128, 128, 128 256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 256)  295168      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, 64, 64, 256)  512         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, 64, 64, 256)  512         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, 64, 64, 256)  512         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, 64, 64, 256)  512         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, 64, 64, 256)  512         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, 64, 64, 256)  512         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, 64, 64, 256)  512         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 512)  0           instance_normalization_18[0][0]  \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, 64, 64, 256)  512         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_19[0][0]  \n",
      "                                                                 leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, 64, 64, 256)  512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_20[0][0]  \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_21 (Inst (None, 64, 64, 256)  512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_21[0][0]  \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 128, 128, 128 589952      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_22 (Inst (None, 128, 128, 128 256         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 256, 64) 73792       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_23 (Inst (None, 256, 256, 64) 128         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 256, 256, 3)  9411        leaky_re_lu_19[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,137,731\n",
      "Trainable params: 8,137,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"g_BA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 256, 256, 64) 9472        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_24 (Inst (None, 256, 256, 64) 128         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 128, 128, 128 73856       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_25 (Inst (None, 128, 128, 128 256         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 64, 64, 256)  295168      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_26 (Inst (None, 64, 64, 256)  512         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_27 (Inst (None, 64, 64, 256)  512         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_28 (Inst (None, 64, 64, 256)  512         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_29 (Inst (None, 64, 64, 256)  512         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_30 (Inst (None, 64, 64, 256)  512         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_31 (Inst (None, 64, 64, 256)  512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_32 (Inst (None, 64, 64, 256)  512         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_32[0][0]  \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_33 (Inst (None, 64, 64, 256)  512         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_33[0][0]  \n",
      "                                                                 leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_34 (Inst (None, 64, 64, 256)  512         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_34[0][0]  \n",
      "                                                                 leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_35 (Inst (None, 64, 64, 256)  512         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_35[0][0]  \n",
      "                                                                 leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 589952      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_36 (Inst (None, 128, 128, 128 256         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 73792       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_37 (Inst (None, 256, 256, 64) 128         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 256, 256, 3)  9411        leaky_re_lu_29[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,137,731\n",
      "Trainable params: 8,137,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "shape of me is:  None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "g_BA (Model)                    (None, 256, 256, 3)  8137731     input_7[0][0]                    \n",
      "                                                                 g_AB[1][0]                       \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "g_AB (Model)                    (None, 256, 256, 3)  8137731     input_5[0][0]                    \n",
      "                                                                 g_BA[1][0]                       \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "d_A (Model)                     (None, 16, 16, 1)    2766659     g_BA[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "d_B (Model)                     (None, 16, 16, 1)    2766659     g_AB[1][0]                       \n",
      "==================================================================================================\n",
      "Total params: 21,808,780\n",
      "Trainable params: 16,275,462\n",
      "Non-trainable params: 5,533,318\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cycle_gan = CycleGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cY0JpMSnXyEN",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 \n",
      "\n",
      "(1, 256, 256, 3) (1, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "cycle_gan.train(epochs=10, batch_size=1, sample_interval=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjICQ9mdBPRm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab_Cycle_GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
