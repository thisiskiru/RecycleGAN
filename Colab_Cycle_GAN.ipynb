{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI9e8cp4XyDD"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "#from OpticalFlow.simplewarp import exect\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import datetime\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "x = 0\n",
    "\n",
    "import math\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "import argparse\n",
    "tf1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "zOPUFn0jXyDM",
    "outputId": "2cd37bbd-5259-4503-8d14-b1d649e1c003"
   },
   "outputs": [],
   "source": [
    "#pip install flow_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtEvh8Liq9ce"
   },
   "outputs": [],
   "source": [
    "import flow_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "013C-lKDXyDQ"
   },
   "source": [
    "\n",
    "# warp class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "IUaPgW6BYDj-",
    "outputId": "c23d851a-34a3-44d5-8a13-908dc07e91cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzqubqceXyDR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pixel_value(img, x, y):\n",
    "    \"\"\"\n",
    "    Utility function to get pixel value for coordinate\n",
    "    vectors x and y from a  4D tensor image.\n",
    "    Input\n",
    "    -----\n",
    "    - img: tensor of shape (B, H, W, C)\n",
    "    - x: flattened tensor of shape (B*H*W, )\n",
    "    - y: flattened tensor of shape (B*H*W, )\n",
    "    Returns\n",
    "    -------\n",
    "    - output: tensor of shape (B, H, W, C)\n",
    "    \"\"\"\n",
    "    shape = tf.shape(x)\n",
    "    batch_size = shape[0]\n",
    "    height = shape[1]\n",
    "    width = shape[2]\n",
    "\n",
    "    batch_idx = tf.range(0, batch_size)\n",
    "    batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "    b = tf.tile(batch_idx, (1, height, width))\n",
    "    indices = tf.stack([b, y, x], 3)\n",
    "\n",
    "    return tf.gather_nd(img, indices)\n",
    "\n",
    "\n",
    "def tf_warp(img, flow):\n",
    "    W, H = tf.cast(tf.shape(img)[2], tf.float32), tf.cast(tf.shape(img)[1], tf.float32)\n",
    "    x, y = tf.meshgrid(tf.range(W), tf.range(H))\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    x = tf.expand_dims(x, -1)\n",
    "\n",
    "    y = tf.expand_dims(y, 0)\n",
    "    y = tf.expand_dims(y, -1)\n",
    "\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    grid = tf.concat([x, y], axis=3)\n",
    "\n",
    "    flows = grid + flow\n",
    "    max_y = tf.cast(H - 1, tf.int32)\n",
    "    max_x = tf.cast(W - 1, tf.int32)\n",
    "    zero = tf.zeros([], dtype=tf.int32)\n",
    "\n",
    "    x = flows[:, :, :, 0]\n",
    "    y = flows[:, :, :, 1]\n",
    "    x0 = x\n",
    "    y0 = y\n",
    "    x0 = tf.cast(x0, tf.int32)\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.cast(y0, tf.int32)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip to range [0, H/W] to not violate img boundaries\n",
    "    x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "    x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "    y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "    y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "\n",
    "    # get pixel value at corner coords\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    # recast as float for delta calculation\n",
    "    x0 = tf.cast(x0, tf.float32)\n",
    "    x1 = tf.cast(x1, tf.float32)\n",
    "    y0 = tf.cast(y0, tf.float32)\n",
    "    y1 = tf.cast(y1, tf.float32)\n",
    "\n",
    "    # calculate deltas\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    # add dimension for addition\n",
    "    wa = tf.expand_dims(wa, axis=3)\n",
    "    wb = tf.expand_dims(wb, axis=3)\n",
    "    wc = tf.expand_dims(wc, axis=3)\n",
    "    wd = tf.expand_dims(wd, axis=3)\n",
    "\n",
    "    # compute output\n",
    "    out = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id])\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n83k-IFfXyDW"
   },
   "source": [
    "# Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMl-Yd96XyDW"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LiteFlowNet2():\n",
    "    def __init__(self, isSintel = True):\n",
    "        self.dblBackward = [0.0, 0.0, 0.0, 5.0, 2.5, 1.25, 0.625]\n",
    "        self.isSintel = isSintel\n",
    "\n",
    "    def feature_extractor(self):\n",
    "        lrelu = lambda x: tf.nn.leaky_relu(x, 0.1)\n",
    "\n",
    "        # module one\n",
    "        m1 = tf.keras.Sequential()\n",
    "        m1.add(tf.keras.layers.Conv2D(filters=32, kernel_size=7,  activation=lrelu, padding='SAME'))\n",
    "\n",
    "        # module two\n",
    "        m2 = tf.keras.Sequential()\n",
    "        m2.add(tf.keras.layers.ZeroPadding2D(padding=(1, 1)))\n",
    "        m2.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2,  activation=lrelu, padding='valid'))\n",
    "        m2.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME'))\n",
    "        m2.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME'))\n",
    "\n",
    "        # module three\n",
    "        m3 = tf.keras.Sequential()\n",
    "        m3.add(tf.keras.layers.ZeroPadding2D(padding=(1, 1)))\n",
    "        m3.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation=lrelu, padding='valid'))\n",
    "        m3.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=lrelu,  padding='SAME'))\n",
    "\n",
    "        # module four\n",
    "        m4 = tf.keras.Sequential()\n",
    "        m4.add(tf.keras.layers.ZeroPadding2D(padding=(1, 1)))\n",
    "        m4.add(tf.keras.layers.Conv2D(filters=96, kernel_size=3, strides=2, activation=lrelu, padding='valid'))\n",
    "        m4.add(tf.keras.layers.Conv2D(filters=96, kernel_size=3, activation=lrelu, padding='SAME'))\n",
    "\n",
    "        # module five\n",
    "        m5 = tf.keras.Sequential()\n",
    "        m5.add(tf.keras.layers.ZeroPadding2D(padding=(1, 1)))\n",
    "        m5.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, activation=lrelu, padding='valid'))\n",
    "\n",
    "        # module six\n",
    "        m6 = tf.keras.Sequential()\n",
    "        m6.add(tf.keras.layers.ZeroPadding2D(padding=(1, 1)))\n",
    "        m6.add(tf.keras.layers.Conv2D(filters=192, kernel_size=3, strides=2, activation=lrelu, padding='valid'))\n",
    "\n",
    "        return [m1, m2, m3, m4, m5, m6]\n",
    "\n",
    "    def group_upconv(self, in1, groups, name, with_bias=False):\n",
    "        # keras don't have an easy way of group conv so use old way\n",
    "        with tf.compat.v1.variable_scope('flownet'):\n",
    "            with tf.compat.v1.variable_scope(name):\n",
    "                filterc = tf.compat.v1.get_variable('filter_w', shape=[4, 4, 1, groups], dtype=tf.float32)\n",
    "                shp = tf.shape(in1)\n",
    "                output_shape = (shp[0], shp[1] * 2, shp[2] * 2, shp[3])\n",
    "                out = tf.nn.conv2d_transpose(in1, filterc, output_shape, strides=[1, 2, 2, 1])\n",
    "                if with_bias:\n",
    "                    bias = tf.compat.v1.get_variable('filter_b', shape=[groups], dtype=tf.float32)\n",
    "                    out = tf.nn.bias_add(out, bias)\n",
    "                return out \n",
    "\n",
    "    def matching(self, tensor_features1, tensor_features2, tensorFlow, int_level, name):\n",
    "        with tf.name_scope(name):\n",
    "            lrelu = lambda x: tf.nn.leaky_relu(x, 0.1)\n",
    "\n",
    "            def module_feat():\n",
    "                return tf.keras.Sequential()\n",
    "                \n",
    "            def module_upcorr(x):\n",
    "                return self.group_upconv(x, 49, name + '/moduleUpcorr')\n",
    "\n",
    "            def module_upflow(x):\n",
    "                return self.group_upconv(x, 2, name + '/moduleUpflow')\n",
    "\n",
    "            def module_main(x):\n",
    "                kernel_size = [0, 0, 0, 5, 5, 3, 3][int_level]                \n",
    "                if kernel_size == 0:\n",
    "                    raise ValueError('Should not be in level %i in Matching layer!' % int_level)\n",
    "                \n",
    "                with tf.name_scope('module_main'):\n",
    "                    conv1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=lrelu, padding='SAME')(x)\n",
    "                    conv2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=lrelu, padding='SAME')(conv1)\n",
    "                    conv3 = tf.keras.layers.Conv2D(filters=96, kernel_size=3, activation=lrelu, padding='SAME')(conv2)                    \n",
    "                    conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=lrelu, padding='SAME')(conv3)\n",
    "                    conv5 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME')(conv4)\n",
    "                    conv6 = tf.keras.layers.Conv2D(filters=2, kernel_size=kernel_size, activation=None, padding='SAME')(conv5)\n",
    "                    return conv6\n",
    "            \n",
    "            if self.dblBackward[int_level] == 0.0:\n",
    "                raise ValueError('Should not be in level %i in Matching layer!' % int_level)\n",
    "            \n",
    "            with tf.name_scope('module_feat'):\n",
    "                m_feat = module_feat()\n",
    "                tensor_features1 = m_feat(tensor_features1)\n",
    "                tensor_features2 = m_feat(tensor_features2)\n",
    "\n",
    "            if tensorFlow is not None:\n",
    "                tensorFlow = module_upflow(tensorFlow)\n",
    "                # warp features\n",
    "                tensor_features2 = tf_warp(tensor_features2, tensorFlow * self.dblBackward[int_level])\n",
    "\n",
    "            if int_level >= 4:\n",
    "                corr = tfa.layers.optical_flow.CorrelationCost(1, 3, 1, 1, 3, 'channels_last')([tensor_features1, tensor_features2])\n",
    "                corr = lrelu(corr)\n",
    "            else:\n",
    "                corr = tfa.layers.optical_flow.CorrelationCost(1, 6, 2, 2, 6, 'channels_last')([tensor_features1, tensor_features2])\n",
    "                corr = lrelu(module_upcorr(corr))\n",
    "\n",
    "            # hack cuz corr cost lost last dimension\n",
    "            corr.set_shape([None, None, None, 49])\n",
    "\n",
    "            return (tensorFlow if tensorFlow is not None else 0.0) + module_main(corr)\n",
    "\n",
    "    def subpixel(self, tensor_features1, tensor_features2, tensorFlow, int_level, name='subpixel'):\n",
    "        with tf.name_scope(name):\n",
    "            lrelu = lambda x: tf.nn.leaky_relu(x, 0.1)\n",
    "\n",
    "            def module_feat():\n",
    "                return tf.keras.Sequential()\n",
    "\n",
    "            def module_main(x):\n",
    "                kernel_size = [0, 0, 0, 5, 5, 3, 3][int_level]\n",
    "                if kernel_size == 0:\n",
    "                    raise ValueError('Should not be in level %i in Subpixel layer!' % int_level)                \n",
    "                \n",
    "                with tf.name_scope(\"module_main\"):\n",
    "                    conv1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=lrelu, padding='SAME')(x)\n",
    "                    conv2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=lrelu, padding='SAME')(conv1)\n",
    "                    conv3 = tf.keras.layers.Conv2D(filters=96, kernel_size=3, activation=lrelu, padding='SAME')(conv2)                    \n",
    "                    conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=lrelu, padding='SAME')(conv3)\n",
    "                    conv5 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME')(conv4)\n",
    "                    conv6 = tf.keras.layers.Conv2D(filters=2, kernel_size=kernel_size, activation=None, padding='SAME')(conv5)\n",
    "                    if int_level > 3 or self.isSintel:\n",
    "                        return conv6\n",
    "                    else:\n",
    "                        return [conv6, conv5]\n",
    "\n",
    "            with tf.name_scope('module_feat'):\n",
    "                mfeat = module_feat()\n",
    "                tensor_features1 = mfeat(tensor_features1)\n",
    "                tensor_features2 = mfeat(tensor_features2)\n",
    "\n",
    "            if self.dblBackward[int_level] == 0:\n",
    "                raise ValueError('Should not be in level %i in Subpixel layer!' % int_level) \n",
    "\n",
    "            tensorFlow1 = tensorFlow * self.dblBackward[int_level]\n",
    "            tensor_features2 = tf_warp(tensor_features2, tensorFlow1)\n",
    "            tens_flow = tf.concat([tensor_features1, tensor_features2, tensorFlow], -1)\n",
    "\n",
    "            if int_level > 3 or self.isSintel:\n",
    "                return (tensorFlow if tensorFlow is not None else 0.0) + module_main(tens_flow)\n",
    "            else:\n",
    "                main_output = module_main(tens_flow)\n",
    "                return [(tensorFlow if tensorFlow is not None else 0.0) + main_output[0], main_output[1]]\n",
    "            \n",
    "\n",
    "    def regularization(self, tensor1, tensor2, tensor_features1, tensorFlow, int_level, name='module_regularization', intermediate_tensor=None):\n",
    "        with tf.name_scope(name):\n",
    "            lrelu = lambda x: tf.nn.leaky_relu(x, 0.1)\n",
    "            int_unfold = [0, 0, 7, 5, 5, 3, 3][int_level]\n",
    "            if int_unfold == 0:\n",
    "                raise ValueError('Should not be in level %i in Regularization layer!' % int_level)            \n",
    "\n",
    "            def module_feat(x):\n",
    "                with tf.name_scope('module_feat'):\n",
    "                    if int_level == 3 or int_level == 4:\n",
    "                        return tf.keras.layers.Conv2D(filters=128, kernel_size=1, activation=lrelu, padding='valid')(x)\n",
    "                    else:\n",
    "                        return x\n",
    "\n",
    "            moduleScale = lambda x: tf.keras.layers.Conv2D(filters=1, kernel_size=1, activation=None, padding='valid')(x)\n",
    "\n",
    "            def module_main(x):\n",
    "                if int_level > 2:\n",
    "                    with tf.name_scope('module_main'):\n",
    "                        conv1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=lrelu, padding='SAME')(x)\n",
    "                        conv2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=lrelu, padding='SAME')(conv1)\n",
    "                        conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=lrelu, padding='SAME')(conv2)\n",
    "                        conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=lrelu, padding='SAME')(conv3)\n",
    "                        conv5 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME')(conv4)\n",
    "                        conv6 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME')(conv5)\n",
    "                        return conv6\n",
    "                else:\n",
    "                    with tf.name_scope('moduleUpflowR'):\n",
    "                        conv6 = self.group_upconv(x, 32, name + '/moduleUpflowR', True)\n",
    "                        return conv6\n",
    "\n",
    "            def module_dist(x):\n",
    "                with tf.name_scope('module_dist'):\n",
    "                    kernel_size = [0, 0, 7, 5, 5, 3, 3][int_level]\n",
    "                    out_channels = [0, 0, 49, 25, 25, 9, 9][int_level]\n",
    "\n",
    "                    if kernel_size == 0 or out_channels == 0:\n",
    "                        raise ValueError('Should not be in level %i in Regularization layer!' % int_level)  \n",
    "\n",
    "                    if int_level >= 5:\n",
    "                        return tf.keras.layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='SAME', activation=None,)(x)\n",
    "                    else:\n",
    "                        x = tf.keras.layers.Conv2D(filters=out_channels, kernel_size=(kernel_size, 1), activation=None,\n",
    "                                                   padding='same')(x)\n",
    "                        x = tf.keras.layers.Conv2D(filters=out_channels, kernel_size=(1, kernel_size), activation=None,\n",
    "                                                   padding='same')(x)\n",
    "                        return x\n",
    "            \n",
    "            if int_level > 2:\n",
    "                if self.dblBackward[int_level] == 0:\n",
    "                    raise ValueError('Should not be in level %i in Regularization layer!' % int_level) \n",
    "                \n",
    "                tensor_diff = tf.sqrt(tf.reduce_sum(tf.square(tensor1 - tf_warp(tensor2, tensorFlow * self.dblBackward[int_level])),\n",
    "                                      axis=3, keepdims=True))\n",
    "                feat = module_feat(tensor_features1)\n",
    "                intermediate_tensor = module_main(tf.concat([tensor_diff,\n",
    "                                                             tensorFlow - tf.reduce_mean(tensorFlow, keepdims=True,\n",
    "                                                                                         axis=[1, 2]),\n",
    "                                                             feat], 3))\n",
    "            else:\n",
    "                intermediate_tensor = self.group_upconv(intermediate_tensor, 32, name + '/moduleUpflowR', True)\n",
    "            \n",
    "            tensor_dist = module_dist(intermediate_tensor)            \n",
    "            tensor_dist = -tf.square(tensor_dist)\n",
    "            tensor_dist = tf.exp(tensor_dist - tf.reduce_max(tensor_dist, axis=3, keepdims=True))\n",
    "\n",
    "            tensor_div = 1. / tf.reduce_sum(tensor_dist, -1, keepdims=True)\n",
    "\n",
    "            tensorScale = []\n",
    "            moduleScaleNames = ['moduleScaleX', 'moduleScaleY']\n",
    "            indices = [0, 1, 2]\n",
    "            for i in range(len(moduleScaleNames)):\n",
    "                with tf.name_scope(moduleScaleNames[i]):\n",
    "                    tensorScale.append(moduleScale(tensor_dist *\n",
    "                                                   tf.image.extract_patches(tensorFlow[..., indices[i]:indices[i+1]],\n",
    "                                                                            [1, int_unfold, int_unfold, 1],\n",
    "                                                                            [1, 1, 1, 1],\n",
    "                                                                            [1, 1, 1, 1],\n",
    "                                                                            \"SAME\")))\n",
    "                \n",
    "            if int_level != 3 or self.isSintel:\n",
    "                return tf.concat([tensorScale[0] * tensor_div, tensorScale[1] * tensor_div], -1)                                                                 \n",
    "            else:\n",
    "                return [tf.concat([tensorScale[0] * tensor_div, tensorScale[1] * tensor_div], -1), intermediate_tensor]\n",
    "\n",
    "\n",
    "    def correct_pan(self, x):\n",
    "        with tf.name_scope('correct_pan'):\n",
    "            lrelu = lambda x: tf.nn.leaky_relu(x, 0.1)\n",
    "            conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=lrelu, padding='SAME')(x)\n",
    "            conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME')(conv1)\n",
    "            conv3 = tf.keras.layers.Conv2D(filters=1, kernel_size=1, activation=None, padding='valid')(conv2)\n",
    "\n",
    "        return tf.nn.tanh(conv3)\n",
    "\n",
    "    def module_chromas(self, x):\n",
    "        with tf.name_scope('module_chromas'):\n",
    "            lrelu = lambda x: tf.nn.leaky_relu(x, 0.1)\n",
    "            conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=lrelu, padding='SAME')(x)\n",
    "            conv2 = tf.keras.layers.Conv2D(filters=2, kernel_size=1, activation=None, padding='valid')(conv1)\n",
    "\n",
    "        return conv2\n",
    "\n",
    "    def __call__(self, tensor1, tensor2, scope='flownet'):\n",
    "        tf.keras.backend.set_floatx('float32')\n",
    "        with tf.name_scope(scope):\n",
    "            tensor1_norm = tensor1 - [[[[0.411618, 0.434631, 0.454253]]]]\n",
    "            tensor2_norm = tensor2 - [[[[0.410782, 0.433645, 0.452793]]]]\n",
    "\n",
    "            m1, m2, m3, m4, m5, m6 = self.feature_extractor()\n",
    "\n",
    "            def shared_feat_modules(x):\n",
    "                with tf.name_scope('feature_extractor'):\n",
    "                    t1 = m1(x)\n",
    "                    t2 = m2(t1)\n",
    "                    t3 = m3(t2)\n",
    "                    t4 = m4(t3)\n",
    "                    t5 = m5(t4)\n",
    "                    t6 = m6(t5)\n",
    "                return [t1, t2, t3, t4, t5, t6]\n",
    "\n",
    "            # Extract features\n",
    "            tensor_feat1 = shared_feat_modules(tensor1_norm)\n",
    "            tensor_feat2 = shared_feat_modules(tensor2_norm)\n",
    "\n",
    "            tensor1 = [tensor1_norm]\n",
    "            tensor2 = [tensor2_norm]\n",
    "            for i in [2, 3, 4, 5]:\n",
    "                tensor1.append(tf.image.resize(tensor1[-1], tf.shape(tensor_feat1[i])[1:3]))\n",
    "                tensor2.append(tf.image.resize(tensor2[-1], tf.shape(tensor_feat2[i])[1:3]))\n",
    "\n",
    "            # Main loop\n",
    "            flow = None\n",
    "            lvls = [2, 3, 4, 5, 6]\n",
    "            for i in [-1, -2, -3, -4]:\n",
    "                flow = self.matching(tensor_feat1[i], tensor_feat2[i], flow, lvls[i], name='matching_%i' % abs(i))\n",
    "                if lvls[i] == 3 and not self.isSintel:\n",
    "                    [flow, intermediate_S_tensor] = self.subpixel(tensor_feat1[i], tensor_feat2[i], flow, lvls[i], name='subpixel_%i' % abs(i))                \n",
    "                    [flow, intermediate_R_tensor] = self.regularization(tensor1[i], tensor2[i], tensor_feat1[i], flow, lvls[i], name='regularization_%i' % abs(i))\n",
    "                else:\n",
    "                    flow = self.subpixel(tensor_feat1[i], tensor_feat2[i], flow, lvls[i], name='subpixel_%i' % abs(i))\n",
    "                    flow = self.regularization(tensor1[i], tensor2[i], tensor_feat1[i], flow, lvls[i], name='regularization_%i' % abs(i))                \n",
    "\n",
    "            # Go through extra layers in Kitti model\n",
    "            if not self.isSintel:\n",
    "                intermediate_S_tensor = self.group_upconv(intermediate_S_tensor, 32, 'subpixel_5/moduleUpflowS', True)\n",
    "                with tf.name_scope(\"subpixel_5/module_main\"):\n",
    "                    intermediate_S_tensor = tf.keras.layers.Conv2D(filters=2, kernel_size=7, activation=None, padding='SAME')(intermediate_S_tensor)\n",
    "                \n",
    "                flow = self.group_upconv(flow, 2, 'matching_5/moduleUpflow', False) + intermediate_S_tensor\n",
    "                i = -5\n",
    "                flow = self.regularization(None, None, tensor_feat1[i], flow, lvls[i], name='regularization_%i' % abs(i), intermediate_tensor=intermediate_R_tensor)\n",
    "\n",
    "            flowr = tf.image.resize(flow, tf.shape(tensor1_norm)[1:3])\n",
    "\n",
    "            return flowr * 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTsv5qeIXyDb"
   },
   "source": [
    "# class eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GR6HCfnNXyDc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "import argparse\n",
    "tf1.disable_eager_execution()\n",
    "'''\n",
    "from PIL import Image\n",
    "from model import LiteFlowNet2\n",
    "from draw_flow import *\n",
    "'''\n",
    "#1000228637703\n",
    "\n",
    "def pad_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        h, w, c = image.shape\n",
    "    else:\n",
    "        h, w = image.shape\n",
    "        c = 1\n",
    "\n",
    "    nh = int(math.ceil(h / 32.) * 32)\n",
    "    nw = int(math.ceil(w / 32.) * 32)\n",
    "\n",
    "    pad_i = np.zeros([nh, nw, c])\n",
    "    pad_i[:h, :w] = image\n",
    "    return pad_i\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "       return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "def initsaver():\n",
    "\t# Create TF session\n",
    "    sess = tf1.Session()\n",
    "    model = LiteFlowNet2(isSintel=True)\n",
    "    tens1 = tf1.placeholder(tf1.float32, shape=[None, None, None, 3])\n",
    "    tens2 = tf1.placeholder(tf1.float32, shape=[None, None, None, 3])\n",
    "    out = model(tens1, tens2)\n",
    "\n",
    "    # Load model\n",
    "    saver = tf1.train.Saver()\n",
    "    #if args.use_Sintel:\n",
    "    saver.restore(sess, \"./models/LiteFlowNet2_Sintel_model\")#\"/content/drive/My Drive/cycleGAN/models/LiteFlowNet2_Sintel_model\")\n",
    "    return sess,out,tens1,tens2\n",
    "\n",
    "\t\n",
    "def floweval(sess,out,inp1,inp2,tens1,tens2):\n",
    "    \n",
    "    w, h = inp1.shape[:2]\n",
    "    inp1 = np.float32(np.expand_dims(pad_image(np.asarray(inp1)[..., ::-1]), 0)) / 255.0\n",
    "    inp2 = np.float32(np.expand_dims(pad_image(np.asarray(inp2)[..., ::-1]), 0)) / 255.0\n",
    "\n",
    "    # input in bgr format\n",
    "    flow = sess.run(out, feed_dict={tens1: inp1, tens2: inp2})[0, :h, :w, :]\n",
    "    \n",
    "    # visualise flow with color model as image and save\n",
    "    flow_color = flow_vis.flow_to_color(flow, convert_to_bgr=False)\n",
    "    flow_image = Image.fromarray(flow_color)\n",
    "    \n",
    "    return flow_image  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lroy2YWsXyDi"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset_name=\"default\", img_res=(256, 256)):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.img_res = img_res\n",
    "        \n",
    "    def load_data(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('/datasets/%s/%s/*' % (self.dataset_name, data_type))#/content/drive/My Drive\n",
    "        \n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "        #print(path)\n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                #img = scipy.misc.imresize(img, self.img_res)\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            else:\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.array(imgs)/127.5 - 1.\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    def load_batch(self, batch_size=1, is_testing=False):\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('/datasets/%s/%sA/*' % (self.dataset_name, data_type))#/content/drive/My Drive/cycleGAN\n",
    "        path_B = glob('/datasets/%s/%sB/*' % (self.dataset_name, data_type))\n",
    "        #print(path_A)\n",
    "        \n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "\n",
    "        # Sample n_batches * batch_size from each path list so that model sees all\n",
    "        # samples from both domains\n",
    "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "                '''\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "                '''\n",
    "                img_A = cv2.resize(img_A, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "                img_B = cv2.resize(img_B, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B\n",
    "\n",
    "    def imread(self, path):\n",
    "        return cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmX4UO-AXyDm"
   },
   "outputs": [],
   "source": [
    "class DataLoader(DataLoader):\n",
    "    global x\n",
    "    def load_data_seq(self, domain, batch_size=1, is_testing=False):\n",
    "        data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))#content/drive/My Drive/cycleGAN/\n",
    "        \n",
    "\n",
    "        batch_images = np.random.choice(path, size=batch_size)\n",
    "        #print(path)\n",
    "        imgs = []\n",
    "        for img_path in batch_images:\n",
    "            img = self.imread(img_path)\n",
    "            if not is_testing:\n",
    "                #img = scipy.misc.imresize(img, self.img_res)\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if np.random.random() > 0.5:\n",
    "                    img = np.fliplr(img)\n",
    "            else:\n",
    "                img = cv2.resize(img, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.array(imgs)/127.5 - 1.\n",
    "\n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kpm_GMxeXyDs"
   },
   "outputs": [],
   "source": [
    "class DataLoader(DataLoader):\n",
    "    def load_batch_seq(self, batch_size=1, is_testing=False):\n",
    "        global x\n",
    "        x=batch_size + x\n",
    "        print('\\n',x,'\\n')\n",
    "        data_type = \"train\" if not is_testing else \"val\"\n",
    "        path_A = glob('./datasets/%s/%sA/*' % (self.dataset_name, data_type))#/content/drive/My Drive/cycleGAN\n",
    "        path_B = glob('./datasets/%s/%sB/*' % (self.dataset_name, data_type))#/content/drive/My Drive/cycleGAN\n",
    "        \n",
    "        self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "        total_samples = self.n_batches * batch_size\n",
    "\n",
    "        # Sample n_batches * batch_size from each path list so that model sees all\n",
    "        # samples from both domains\n",
    "        #for i in range(n_batches):\n",
    "        ba_A = path_A[x - batch_size : x]\n",
    "        ba_B = path_B[x - batch_size : x]\n",
    "            \n",
    "            \n",
    "        #path_A = np.random.choice(path_A, total_samples, replace=False)\n",
    "        #path_B = np.random.choice(path_B, total_samples, replace=False)\n",
    "\n",
    "        for i in range(self.n_batches-1):\n",
    "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "            imgs_A, imgs_B = [], []\n",
    "            for img_A, img_B in zip(batch_A, batch_B):\n",
    "                img_A = self.imread(img_A)\n",
    "                img_B = self.imread(img_B)\n",
    "                '''\n",
    "\n",
    "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
    "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
    "                '''\n",
    "                img_A = cv2.resize(img_A, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "                img_B = cv2.resize(img_B, self.img_res, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                if not is_testing and np.random.random() > 0.5:\n",
    "                        img_A = np.fliplr(img_A)\n",
    "                        img_B = np.fliplr(img_B)\n",
    "\n",
    "                imgs_A.append(img_A)\n",
    "                imgs_B.append(img_B)\n",
    "\n",
    "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
    "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
    "\n",
    "            yield imgs_A, imgs_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mI8wUHMmXyDw"
   },
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #sess and model of flownet2\n",
    "        self.sess,self.out,self.tens1,self.tens2=initsaver()       \n",
    "        self.img_cols=256\n",
    "        self.img_rows=256\n",
    "        self.channels = 3 \n",
    "        #flownet2 = initflow()\n",
    "        epsilon: int = 1e-5\n",
    "        self.img_shape = (self.img_rows, self.img_cols,self.channels) \n",
    "        self.dataset_name = '01'\n",
    "        \n",
    "        self.data_loader=DataLoader(self.dataset_name)\n",
    "        #self.mc=myclass()\n",
    "        \n",
    "        \n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1) \n",
    "        self.gf = 32                                                    \n",
    "        self.df = 64   \n",
    "        \n",
    "        \"\"\"\n",
    "        hyperparameters\n",
    "         1, lambda_cycle — controls howstrictly the cycle-consistency loss is enforced.\n",
    "         2, lambda_id — influences identity loss\n",
    "         3, lambda_opt — control optical flow difference between the two network\n",
    "        \"\"\"\n",
    "        self.lambda_cycle = 10.0  \n",
    "        self.lambda_id = 0.9 * self.lambda_cycle \n",
    "        self.lambda_opt = 10.0 \n",
    "        \n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        self.d_A = self.build_discriminator('d_A')\n",
    "        self.d_A.summary()\n",
    "        \n",
    "        self.d_B = self.build_discriminator('d_B')\n",
    "        self.d_B.summary()\n",
    "        \n",
    "        self.d_A.compile(loss = 'mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "        self.d_B.compile(loss = 'mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "        \n",
    "        self.g_AB = self.build_generator('g_AB')\n",
    "        self.g_AB.summary()\n",
    "        self.g_BA = self.build_generator('g_BA')\n",
    "        self.g_BA.summary()\n",
    "        \n",
    "        img_A = tf.keras.Input(shape=self.img_shape)\n",
    "        opt_A = tf.keras.Input(shape=self.img_shape)\n",
    "        img_B = tf.keras.Input(shape=self.img_shape)\n",
    "        opt_B = tf.keras.Input(shape=self.img_shape)\n",
    "        \n",
    "        print('shape of me is: ',img_A.shape[0])\n",
    "        \n",
    "        fake_B = self.g_AB(img_A)                                  \n",
    "        fake_A = self.g_BA(img_B)\n",
    "        #fake_B =myclass.flowwarp(fake_A,img_A)\n",
    "        #opt_A = exect(flownet2,[img_A,img_A])\n",
    "        #opt_B = img_B[0]  \n",
    "    \n",
    "        reconstr_A = self.g_BA(fake_B)                             \n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        \n",
    "        '''\n",
    "        opt_A = exect(self.flownet2,[op1,op1]) \n",
    "        \n",
    "        \n",
    "        opt_B = exect(self.flownet2,[self.prevB,op2])\n",
    "        opt_Are = exect(self.flownet2,[self.prevAre,reconstr_A])\n",
    "        opt_Bre = exect(self.flownet2,[self.prevBre,reconstr_B])\n",
    "        '''\n",
    "        \n",
    "        self.prevA = img_A\n",
    "        self.prevB = img_B\n",
    "        \n",
    "        self.prevAre = reconstr_A\n",
    "        self.prevBre = reconstr_B\n",
    "        \n",
    "        img_A_id = self.g_BA(img_A)                                \n",
    "        img_B_id = self.g_AB(img_B)\n",
    "        \n",
    "        self.d_A.trainable = False                                 \n",
    "        self.d_B.trainable = False\n",
    "        \n",
    "        valid_A = self.d_A(fake_A)                                 \n",
    "        valid_B = self.d_B(fake_B)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.combined = tf.keras.Model(inputs=[img_A, img_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,    \n",
    "                                       img_A_id, img_B_id]) \n",
    "        self.combined.compile(loss=['mse', 'mse','mae', 'mae','mae', 'mae'],\n",
    "                              loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_id, \n",
    "                                            self.lambda_id],\n",
    "                              optimizer=optimizer)\n",
    "        self.combined.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zopjCHfoXyD0"
   },
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    @staticmethod  \n",
    "    def conv2d(layer_input, num_Filter, f_size=4, Strides=1,Ins_Norm=True,Padding='same'):\n",
    "        d = layers.Conv2D(num_Filter,kernel_size=f_size,strides=Strides, padding=Padding)(layer_input)\n",
    "        if Ins_Norm:\n",
    "            d = tfa.layers.InstanceNormalization(axis=3, center=True, epsilon=1e-5)(d)\n",
    "            #d = layers.BatchNormalization()(d)\n",
    "        d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "        return d\n",
    "    \n",
    "    @staticmethod\n",
    "    def resNET(layer_input, skip_input, filters, f_size=4,Strides=1, dropout_rate=0):\n",
    "        \n",
    "        r = layers.Conv2D(filters, kernel_size=f_size, strides=Strides, padding='same', activation='relu')(layer_input)\n",
    "        #r = layers.BatchNormalization()(r)\n",
    "        r = tfa.layers.InstanceNormalization(axis=3, center=True, epsilon=1e-5)(r)\n",
    "        r = layers.Concatenate()([r,skip_input])\n",
    "        return r\n",
    "  \n",
    "    @staticmethod\n",
    "    def deconv2d(layer_input, num_Filter, f_size=4, Strides=1,Ins_Norm=True,Padding='same'):\n",
    "        d = layers.Conv2DTranspose(num_Filter,kernel_size=f_size,strides=Strides, padding=Padding)(layer_input)\n",
    "        if Ins_Norm:\n",
    "            #d = layers.BatchNormalization()(d)\n",
    "            d = tfa.layers.InstanceNormalization(axis=3, center=True, epsilon=1e-5)(d)\n",
    "        d = layers.LeakyReLU(alpha=0.2)(d)\n",
    "        return d\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_zqezVwXyD5"
   },
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def build_generator(self,name):\n",
    "        d0 = tf.keras.Input(self.img_shape)  \n",
    "        ''' ConvNET '''\n",
    "        d1 = self.conv2d(d0, 64, 7)              \n",
    "        d2 = self.conv2d(d1, 128, 3, 2, Ins_Norm=True)          \n",
    "        d3 = self.conv2d(d2, 256, 3, 2, Ins_Norm=True)\n",
    "        \n",
    "        ''' Residual Block '''\n",
    "        r1 = self.conv2d(d3, 256, 3, 1)\n",
    "        r2 = self.conv2d(r1, 256, 3, 1)\n",
    "        r3 = self.conv2d(r2, 256, 3, 1)\n",
    "        r4 = self.conv2d(r3, 256, 3, 1)\n",
    "        r5 = self.conv2d(r4, 256, 3, 1)\n",
    "        \n",
    "        r6 = self.resNET(r5, r4, 256, 3, 1)\n",
    "        r7 = self.resNET(r6, r3, 256, 3, 1)\n",
    "        r8 = self.resNET(r7, r2, 256, 3, 1)\n",
    "        r9 = self.resNET(r8, r1, 256, 3, 1)\n",
    "        \n",
    "        u1 = self.deconv2d(r9, 128, 3, 2, True)\n",
    "        u2 = self.deconv2d(u1, 64, 3, 2, True)\n",
    "                        \n",
    "        output_img = layers.Conv2D(self.channels, kernel_size=7, strides=(1,1), padding='same',activation='tanh')(u2) \n",
    "        x=tf.keras.Model(d0, output_img,name=name)\n",
    "        #x.Summary()\n",
    "        return x\n",
    "    \n",
    "    def build_discriminator(self,n):\n",
    "        #conv2d(layer_input, num_Filter, f_size=4, Strides=1,Ins_Norm=True,Padding='same'):\n",
    "        img=tf.keras.Input(self.img_shape)\n",
    "        d1 = self.conv2d(img, 64, 4, 2)\n",
    "        d2 = self.conv2d(d1, 128, 4, 2)\n",
    "        d3 = self.conv2d(d2, 256, 4, 2)\n",
    "        d4 = self.conv2d(d3, 512, 4, 2)  \n",
    "        d5 = self.conv2d(d4, 1, 4, 1)  \n",
    "       \n",
    "        x=tf.keras.Model(img,d5,name=n)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSAB_U7wXyD-"
   },
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        r, c = 2, 3\n",
    "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
    "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)    \n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(imgs_A)\n",
    "        #fake_A = self.g_BA.predict(imgs_B)\n",
    "        '''\n",
    "        cheeck here\n",
    "        '''\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                #print(gen_imgs[cnt].shape)\n",
    "                b,g,r = cv2.split(gen_imgs[cnt])       # get b,g,r\n",
    "                im_rgb = cv2.merge([r,g,b])     # switch it to rgb\n",
    "                \n",
    "                axs[i,j].imshow((im_rgb * 255).astype(np.uint8))\n",
    "                axs[i, j].set_title(titles[j])\n",
    "                axs[i,j].axis('on')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kep9ICe9XyEC"
   },
   "outputs": [],
   "source": [
    "class CycleGAN(CycleGAN):\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch_seq(batch_size)):\n",
    "               \n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "                # Translate images to opposite domain\n",
    "                \n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "                print(fake_A.shape,imgs_A.shape)\n",
    "                \n",
    "                ###################\n",
    "                fake_A = floweval(self.sess,self.out,fake_A[0],fake_A[0],self.tens1,self.tens2)\n",
    "                ###################\n",
    "                \n",
    "                #imagewarp()\n",
    "                \n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "                # Total discriminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "                \n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "                #print(d_loss,dA_loss,dB_loss)\n",
    "                # Train the generators\n",
    "                print(self.combined.metrics_names)\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
    "                                                      [valid, valid,\n",
    "                                                       imgs_A, imgs_B,\n",
    "                                                       imgs_A, imgs_B])\n",
    "                \n",
    "                print(g_loss)\n",
    "                \n",
    "                #print('g_loss: ',g_loss)\n",
    "                # If at save interval => plot the generated image samples\n",
    "                \n",
    "                if batch_i % sample_interval * 50 == 0:\n",
    "                    self.sample_images(epoch, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jXNeVPHQXyEJ",
    "outputId": "c4c59f25-cf1e-42db-bc16-91bac584dd50",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\thisiskiru\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Restoring parameters from ./models/LiteFlowNet2_Sintel_model\n",
      "Model: \"d_A\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "instance_normalization (Inst (None, 128, 128, 64)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 32, 32, 256)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 16, 16, 1)         8193      \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 16, 16, 1)         2         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,766,659\n",
      "Trainable params: 2,766,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"d_B\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "instance_normalization_5 (In (None, 128, 128, 64)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_6 (In (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_7 (In (None, 32, 32, 256)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "instance_normalization_8 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 16, 16, 1)         8193      \n",
      "_________________________________________________________________\n",
      "instance_normalization_9 (In (None, 16, 16, 1)         2         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 16, 16, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,766,659\n",
      "Trainable params: 2,766,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"g_AB\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 256, 256, 64) 9472        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, 256, 256, 64) 128         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 128, 128, 128 73856       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, 128, 128, 128 256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 256)  295168      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, 64, 64, 256)  512         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, 64, 64, 256)  512         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, 64, 64, 256)  512         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, 64, 64, 256)  512         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, 64, 64, 256)  512         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, 64, 64, 256)  512         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, 64, 64, 256)  512         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 512)  0           instance_normalization_18[0][0]  \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, 64, 64, 256)  512         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_19[0][0]  \n",
      "                                                                 leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, 64, 64, 256)  512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_20[0][0]  \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_21 (Inst (None, 64, 64, 256)  512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_21[0][0]  \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 128, 128, 128 589952      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_22 (Inst (None, 128, 128, 128 256         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 256, 64) 73792       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_23 (Inst (None, 256, 256, 64) 128         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 256, 256, 3)  9411        leaky_re_lu_19[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,137,731\n",
      "Trainable params: 8,137,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"g_BA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 256, 256, 64) 9472        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_24 (Inst (None, 256, 256, 64) 128         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 128, 128, 128 73856       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_25 (Inst (None, 128, 128, 128 256         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 64, 64, 256)  295168      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_26 (Inst (None, 64, 64, 256)  512         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_27 (Inst (None, 64, 64, 256)  512         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_28 (Inst (None, 64, 64, 256)  512         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_29 (Inst (None, 64, 64, 256)  512         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_30 (Inst (None, 64, 64, 256)  512         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_31 (Inst (None, 64, 64, 256)  512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 64, 64, 256)  0           instance_normalization_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 64, 64, 256)  590080      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_32 (Inst (None, 64, 64, 256)  512         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_32[0][0]  \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_33 (Inst (None, 64, 64, 256)  512         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_33[0][0]  \n",
      "                                                                 leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_34 (Inst (None, 64, 64, 256)  512         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_34[0][0]  \n",
      "                                                                 leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_35 (Inst (None, 64, 64, 256)  512         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 512)  0           instance_normalization_35[0][0]  \n",
      "                                                                 leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 589952      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_36 (Inst (None, 128, 128, 128 256         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 128, 128, 128 0           instance_normalization_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 73792       leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_37 (Inst (None, 256, 256, 64) 128         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 256, 256, 64) 0           instance_normalization_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 256, 256, 3)  9411        leaky_re_lu_29[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,137,731\n",
      "Trainable params: 8,137,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "shape of me is:  None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "g_BA (Model)                    (None, 256, 256, 3)  8137731     input_7[0][0]                    \n",
      "                                                                 g_AB[1][0]                       \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "g_AB (Model)                    (None, 256, 256, 3)  8137731     input_5[0][0]                    \n",
      "                                                                 g_BA[1][0]                       \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "d_A (Model)                     (None, 16, 16, 1)    2766659     g_BA[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "d_B (Model)                     (None, 16, 16, 1)    2766659     g_AB[1][0]                       \n",
      "==================================================================================================\n",
      "Total params: 21,808,780\n",
      "Trainable params: 16,275,462\n",
      "Non-trainable params: 5,533,318\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cycle_gan = CycleGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cY0JpMSnXyEN",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 \n",
      "\n",
      "(1, 256, 256, 3) (1, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "cycle_gan.train(epochs=10, batch_size=1, sample_interval=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjICQ9mdBPRm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colab_Cycle_GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
